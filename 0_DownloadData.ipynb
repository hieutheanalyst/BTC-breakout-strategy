{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ccxt\n",
    "import pandas as pd\n",
    "from datetime import datetime, timezone\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data from 2017-01-01 00:00:00+00:00...\n",
      "Fetching data from 2017-12-17 18:00:00.001000+00:00...\n",
      "Fetching data from 2018-01-28 11:00:00.001000+00:00...\n",
      "Fetching data from 2018-03-12 12:00:00.001000+00:00...\n",
      "Fetching data from 2018-04-23 04:00:00.001000+00:00...\n",
      "Fetching data from 2018-06-03 20:00:00.001000+00:00...\n",
      "Fetching data from 2018-07-16 06:00:00.001000+00:00...\n",
      "Fetching data from 2018-08-26 22:00:00.001000+00:00...\n",
      "Fetching data from 2018-10-07 14:00:00.001000+00:00...\n",
      "Fetching data from 2018-11-18 16:00:00.001000+00:00...\n",
      "Fetching data from 2018-12-30 08:00:00.001000+00:00...\n",
      "Fetching data from 2019-02-10 00:00:00.001000+00:00...\n",
      "Fetching data from 2019-03-23 22:00:00.001000+00:00...\n",
      "Fetching data from 2019-05-04 14:00:00.001000+00:00...\n",
      "Fetching data from 2019-06-15 16:00:00.001000+00:00...\n",
      "Fetching data from 2019-07-27 08:00:00.001000+00:00...\n",
      "Fetching data from 2019-09-07 08:00:00.001000+00:00...\n",
      "Fetching data from 2019-10-19 00:00:00.001000+00:00...\n",
      "Fetching data from 2019-11-29 20:00:00.001000+00:00...\n",
      "Fetching data from 2020-01-10 12:00:00.001000+00:00...\n",
      "Fetching data from 2020-02-21 10:00:00.001000+00:00...\n",
      "Fetching data from 2020-04-03 03:00:00.001000+00:00...\n",
      "Fetching data from 2020-05-14 21:00:00.001000+00:00...\n",
      "Fetching data from 2020-06-25 13:00:00.001000+00:00...\n",
      "Fetching data from 2020-08-06 08:00:00.001000+00:00...\n",
      "Fetching data from 2020-09-17 00:00:00.001000+00:00...\n",
      "Fetching data from 2020-10-28 16:00:00.001000+00:00...\n",
      "Fetching data from 2020-12-09 09:00:00.001000+00:00...\n",
      "Fetching data from 2021-01-20 06:00:00.001000+00:00...\n",
      "Fetching data from 2021-03-02 23:00:00.001000+00:00...\n",
      "Fetching data from 2021-04-13 16:00:00.001000+00:00...\n",
      "Fetching data from 2021-05-25 13:00:00.001000+00:00...\n",
      "Fetching data from 2021-07-06 05:00:00.001000+00:00...\n",
      "Fetching data from 2021-08-17 01:00:00.001000+00:00...\n",
      "Fetching data from 2021-09-27 17:00:00.001000+00:00...\n",
      "Fetching data from 2021-11-08 11:00:00.001000+00:00...\n",
      "Fetching data from 2021-12-20 03:00:00.001000+00:00...\n",
      "Fetching data from 2022-01-30 19:00:00.001000+00:00...\n",
      "Fetching data from 2022-03-13 11:00:00.001000+00:00...\n",
      "Fetching data from 2022-04-24 03:00:00.001000+00:00...\n",
      "Fetching data from 2022-06-04 19:00:00.001000+00:00...\n",
      "Fetching data from 2022-07-16 11:00:00.001000+00:00...\n",
      "Fetching data from 2022-08-27 03:00:00.001000+00:00...\n",
      "Fetching data from 2022-10-07 19:00:00.001000+00:00...\n",
      "Fetching data from 2022-11-18 11:00:00.001000+00:00...\n",
      "Fetching data from 2022-12-30 03:00:00.001000+00:00...\n",
      "Fetching data from 2023-02-09 19:00:00.001000+00:00...\n",
      "Fetching data from 2023-03-23 11:00:00.001000+00:00...\n",
      "Fetching data from 2023-05-04 04:00:00.001000+00:00...\n",
      "Fetching data from 2023-06-14 20:00:00.001000+00:00...\n",
      "Fetching data from 2023-07-26 12:00:00.001000+00:00...\n",
      "Fetching data from 2023-09-06 04:00:00.001000+00:00...\n",
      "Fetching data from 2023-10-17 20:00:00.001000+00:00...\n",
      "Fetching data from 2023-11-28 12:00:00.001000+00:00...\n",
      "Fetching data from 2024-01-09 04:00:00.001000+00:00...\n",
      "Fetching data from 2024-02-19 20:00:00.001000+00:00...\n",
      "Fetching data from 2024-04-01 12:00:00.001000+00:00...\n",
      "Fetching data from 2024-05-13 04:00:00.001000+00:00...\n",
      "Fetching data from 2024-06-23 20:00:00.001000+00:00...\n",
      "Fetching data from 2024-08-04 12:00:00.001000+00:00...\n",
      "Fetching data from 2024-09-15 04:00:00.001000+00:00...\n",
      "Fetching data from 2024-10-26 20:00:00.001000+00:00...\n",
      "Fetching data from 2024-12-07 12:00:00.001000+00:00...\n",
      "Fetching data from 2024-12-16 06:00:00.001000+00:00...\n"
     ]
    }
   ],
   "source": [
    "# Initialize Binance API\n",
    "exchange = ccxt.binance()\n",
    "\n",
    "# Parameters\n",
    "symbol = 'BNB/USDT'\n",
    "timeframe = '1h'  # 1-hour data\n",
    "start_date = '2017-01-01'  # Binance's data starts in 2017\n",
    "end_date = '2024-12-31'\n",
    "\n",
    "# Convert date to timestamps\n",
    "start_timestamp = exchange.parse8601(f'{start_date}T00:00:00Z')\n",
    "end_timestamp = exchange.parse8601(f'{end_date}T00:00:00Z')\n",
    "\n",
    "# Fetch historical data\n",
    "all_data = []\n",
    "while start_timestamp < end_timestamp:\n",
    "    print(f\"Fetching data from {datetime.fromtimestamp(start_timestamp / 1000, tz=timezone.utc)}...\")\n",
    "    ohlcv = exchange.fetch_ohlcv(symbol, timeframe, since=start_timestamp, limit=1000)\n",
    "    if not ohlcv:\n",
    "        break\n",
    "    all_data += ohlcv\n",
    "    start_timestamp = ohlcv[-1][0] + 1\n",
    "\n",
    "# Create DataFrame\n",
    "columns = ['timestamp', 'Open', 'High', 'Low', 'Close', 'Volume']\n",
    "data = pd.DataFrame(all_data, columns=columns)\n",
    "data['timestamp'] = pd.to_datetime(data['timestamp'], unit='ms')\n",
    "data.set_index('timestamp', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-11-06 03:00:00</th>\n",
       "      <td>1.5000</td>\n",
       "      <td>1.7990</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>1.7000</td>\n",
       "      <td>649.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-06 04:00:00</th>\n",
       "      <td>1.3000</td>\n",
       "      <td>1.6500</td>\n",
       "      <td>1.3000</td>\n",
       "      <td>1.6479</td>\n",
       "      <td>8147.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-06 05:00:00</th>\n",
       "      <td>1.5457</td>\n",
       "      <td>1.5525</td>\n",
       "      <td>1.5455</td>\n",
       "      <td>1.5458</td>\n",
       "      <td>6628.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-06 06:00:00</th>\n",
       "      <td>1.5458</td>\n",
       "      <td>1.6810</td>\n",
       "      <td>1.5387</td>\n",
       "      <td>1.6810</td>\n",
       "      <td>22767.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-06 07:00:00</th>\n",
       "      <td>1.6809</td>\n",
       "      <td>1.6809</td>\n",
       "      <td>1.6000</td>\n",
       "      <td>1.6250</td>\n",
       "      <td>14938.73</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Open    High     Low   Close    Volume\n",
       "timestamp                                                    \n",
       "2017-11-06 03:00:00  1.5000  1.7990  0.5000  1.7000    649.12\n",
       "2017-11-06 04:00:00  1.3000  1.6500  1.3000  1.6479   8147.72\n",
       "2017-11-06 05:00:00  1.5457  1.5525  1.5455  1.5458   6628.20\n",
       "2017-11-06 06:00:00  1.5458  1.6810  1.5387  1.6810  22767.90\n",
       "2017-11-06 07:00:00  1.6809  1.6809  1.6000  1.6250  14938.73"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display the first few rows\n",
    "display(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 62210 entries, 2017-11-06 03:00:00 to 2024-12-16 06:00:00\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   Open    62210 non-null  float64\n",
      " 1   High    62210 non-null  float64\n",
      " 2   Low     62210 non-null  float64\n",
      " 3   Close   62210 non-null  float64\n",
      " 4   Volume  62210 non-null  float64\n",
      "dtypes: float64(5)\n",
      "memory usage: 2.8 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "if data.isnull().values.any():\n",
    "    print(\"There are missing values, baby. Cleaning them...\")\n",
    "    data.dropna(inplace=True)\n",
    "\n",
    "# Check data consistency\n",
    "print(data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In-sample data:\n",
      "                       Open    High     Low   Close   Volume\n",
      "timestamp                                                   \n",
      "2017-11-06 03:00:00  1.5000  1.7990  0.5000  1.7000   649.12\n",
      "2017-11-06 04:00:00  1.3000  1.6500  1.3000  1.6479  8147.72\n",
      "2017-11-06 05:00:00  1.5457  1.5525  1.5455  1.5458  6628.20\n",
      "                      Open   High    Low  Close    Volume\n",
      "timestamp                                                \n",
      "2022-12-31 21:00:00  247.0  247.5  246.9  247.0  5611.203\n",
      "2022-12-31 22:00:00  247.0  247.3  245.9  246.3  5626.283\n",
      "2022-12-31 23:00:00  246.3  246.9  246.0  246.3  4340.382\n",
      "------------\n",
      "Out-of-sample data:\n",
      "                      Open   High    Low  Close    Volume\n",
      "timestamp                                                \n",
      "2023-01-01 00:00:00  246.3  246.7  245.5  245.7  4233.967\n",
      "2023-01-01 01:00:00  245.8  246.0  245.5  245.8  2424.087\n",
      "2023-01-01 02:00:00  245.8  245.9  245.2  245.3  3971.279\n",
      "                       Open    High     Low   Close    Volume\n",
      "timestamp                                                    \n",
      "2024-12-16 04:00:00  711.26  714.00  710.19  713.27  7833.165\n",
      "2024-12-16 05:00:00  713.26  714.98  711.23  714.83  7397.746\n",
      "2024-12-16 06:00:00  714.84  716.69  714.45  716.19  4505.753\n"
     ]
    }
   ],
   "source": [
    "# Define split dates\n",
    "in_sample_end = '2022-12-31'\n",
    "out_of_sample_start = '2023-01-01'\n",
    "\n",
    "# Split data\n",
    "in_sample_data = data[:in_sample_end]\n",
    "out_of_sample_data = data[out_of_sample_start:]\n",
    "\n",
    "# Check the splits\n",
    "print(\"In-sample data:\", in_sample_data.head(3), in_sample_data.tail(3), sep=\"\\n\")\n",
    "print('------------')\n",
    "print(\"Out-of-sample data:\", out_of_sample_data.head(3), out_of_sample_data.tail(3), sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the base symbol\n",
    "base_symbol = symbol.split('/')[0]\n",
    "\n",
    "# Save to CSV with dynamic file names\n",
    "in_sample_data.to_csv(f'{base_symbol}_in_sample_data.csv')\n",
    "out_of_sample_data.to_csv(f'{base_symbol}_out_of_sample_data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
